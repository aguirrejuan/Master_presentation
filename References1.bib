@article{ WOS:000613005100038,
Author = {Babaoglu, Gulcin and Kilicaslan, Banu and Yilbas, Aysun Ankay and
   Celebioglu, Bilge},
Title = {Effects of different analgesic methods used for vaginal delivery on
   mothers and fetuses},
Journal = {TURKISH JOURNAL OF MEDICAL SCIENCES},
Year = {2020},
Volume = {50},
Number = {4},
Pages = {930-936},
Abstract = {Background/aim: Knowledge regarding pain relief during labor remains
   insufficient. We aimed to determine and compare the effectiveness and
   safety of epidural analgesia, combined spinal-epidural analgesia, and
   parenteral meperidine on both mothers and fetuses.
   Materials and methods: This study was designed as an observational
   case-control study. We collected prospective data from patients whose
   labor pain management was conducted with meperidine in addition to
   retrospective cohort data of neuraxial methods; 138 patients were
   enrolled. Epidural analgesia group consisted of 68 patients, whereas
   combined spinal-epidural (CSE) analgesia group and meperidine group
   consisted of 50 and 20 patients, respectively. We compared the delivery
   patterns, labor durations, pain levels, side effects, maternal
   satisfaction levels, and neonatal outcomes of the various pain
   management methods.
   Results: Patient demographics, duration of first, second, and third
   labor stages, and instrumental delivery rates were comparable among
   groups (P > 0.05). Cesarean section tended to be less frequent in the
   CSE group. In the meperidine group, visual analog scale (VAS) values and
   sedation were significantly higher (P < 0.001) and maternal satisfaction
   lower (P < 0.001). Hypotension tended to be more frequent in the
   meperidine group. APGAR scores at the 1st and 5th min were similar among
   the groups and between meperidine subgroups defined by three different
   administration times (<1 h, 1-4 h, >4 h; P > 0.05).
   Conclusion: Neuraxial methods had no effect on instrumental delivery
   rates. CSE represented a near significant risk reduction in cesarean
   section. Our results demonstrated that regional analgesia methods were
   reasonably safe for both mother and fetus, and regional analgesia
   methods resulted in greater maternal satisfaction and pain control
   compared to meperidine.},
Publisher = {TUBITAK SCIENTIFIC \& TECHNICAL RESEARCH COUNCIL TURKEY},
Address = {ATATURK BULVARI NO 221, KAVAKLIDERE, ANKARA, 00000, TURKEY},
Type = {Article},
Language = {English},
Affiliation = {Babaoglu, G (Corresponding Author), Hacettepe Univ, Fac Med, Dept Anesthesiol \& Reanimat, Ankara, Turkey.
   Babaoglu, Gulcin; Kilicaslan, Banu; Yilbas, Aysun Ankay; Celebioglu, Bilge, Hacettepe Univ, Fac Med, Dept Anesthesiol \& Reanimat, Ankara, Turkey.},
DOI = {10.3906/sag-1911-61},
ISSN = {1300-0144},
EISSN = {1303-6165},
Keywords = {Labor pain; meperidine; neuraxial analgesia},
Keywords-Plus = {EPIDURAL ANALGESIA; LABOR ANALGESIA; CHILDBIRTH; PETHIDINE; OUTCOMES;
   HEALTH; PAIN},
Research-Areas = {General \& Internal Medicine},
Web-of-Science-Categories  = {Medicine, General \& Internal},
Author-Email = {gulcinpektasli@gmail.com},
ResearcherID-Numbers = {Kilicaslan, Banu/I-9846-2013
   },
ORCID-Numbers = {Kilicaslan, Banu/0000-0003-3295-9999
   Celebioglu, Bilge/0000-0001-9198-8357},
Number-of-Cited-References = {29},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Turk. J. Med. Sci.},
Doc-Delivery-Number = {PZ8NX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000613005100038},
OA = {Green Published},
DA = {2022-11-10},
}



@Article{s21227741,
AUTHOR = {Jimenez-Castaño, Cristian Alfonso and Álvarez-Meza, Andrés Marino and Aguirre-Ospina, Oscar David and Cárdenas-Peña, David Augusto and Orozco-Gutiérrez, Álvaro Angel},
TITLE = {Random Fourier Features-Based Deep Learning Improvement with Class Activation Interpretability for Nerve Structure Segmentation},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7741},
URL = {https://www.mdpi.com/1424-8220/21/22/7741},
PubMedID = {34833817},
ISSN = {1424-8220},
ABSTRACT = {Peripheral nerve blocking (PNB) is a standard procedure to support regional anesthesia. Still, correct localization of the nerve’s structure is needed to avoid adverse effects; thereby, ultrasound images are used as an aid approach. In addition, image-based automatic nerve segmentation from deep learning methods has been proposed to mitigate attenuation and speckle noise ultrasonography issues. Notwithstanding, complex architectures highlight the region of interest lacking suitable data interpretability concerning the learned features from raw instances. Here, a kernel-based deep learning enhancement is introduced for nerve structure segmentation. In a nutshell, a random Fourier features-based approach was utilized to complement three well-known semantic segmentation architectures, e.g., fully convolutional network, U-net, and ResUnet. Moreover, two ultrasound image datasets for PNB were tested. Obtained results show that our kernel-based approach provides a better generalization capability from image segmentation-based assessments on different nerve structures. Further, for data interpretability, a semantic segmentation extension of the GradCam++ for class-activation mapping was used to reveal relevant learned features separating between nerve and background. Thus, our proposal favors both straightforward (shallow) and complex architectures (deeper neural networks).},
DOI = {10.3390/s21227741}
}






@article {PMID:25232864,
	Title = {Distal infrared thermography and skin temperature after ultrasound-guided interscalene brachial plexus block: a prospective observational study},
	Author = {Asghar, Semera and Bjerregaard, Lars S and Lundstrøm, Lars H and Lund, Jørgen and Jenstrup, Morten T and Lange, Kai H W},
	DOI = {10.1097/eja.0000000000000152},
	Number = {11},
	Volume = {31},
	Month = {November},
	Year = {2014},
	Journal = {European journal of anaesthesiology},
	ISSN = {0265-0215},
	Pages = {626—634},
	Abstract = {&lt;h4&gt;Background&lt;/h4&gt;Increases in skin temperature may be used as an early predictor of the success of interscalene brachial plexus block (IBPB), but we lack detailed information on the thermographic response.&lt;h4&gt;Objective&lt;/h4&gt;To investigate and characterise the thermographic response after IBPBs.&lt;h4&gt;Design&lt;/h4&gt;Prospective observational study.&lt;h4&gt;Setting&lt;/h4&gt;University hospital and private hospital.&lt;h4&gt;Patients&lt;/h4&gt;Twenty-nine male and 17 female patients scheduled for ambulatory shoulder surgery. Exclusion criteria were age less than 18 years, body weight more than 120 kg and any coagulation abnormality.&lt;h4&gt;Interventions&lt;/h4&gt;Infrared thermographic imaging of the hand before and at 1 min intervals for 30 min after an ultrasound-guided IBPB with 20 ml ropivacaine 7.5 mg ml. Cooling of both hands was performed to standardise measurements.&lt;h4&gt;Main outcome measures&lt;/h4&gt;Thermographic changes in skin temperature on the dorsum of the hand.&lt;h4&gt;Results&lt;/h4&gt;Forty-four blocks were successful and two were failures. Four thermographic patterns were observed after successful blocks: the increase in skin temperature was restricted to the thumb (n = 5); increase in skin temperature of the thumb and the second digit (n = 11); increase in skin temperature of the thumb, the second and fifth digits (n = 4); and an increase in skin temperature in all parts of the hand (n = 24). All successful blocks demonstrated a significant (P &lt; 0.0001) increase in median (range) of distal skin temperature of the thumb of 6.6°C (0.7 to 17.2) by 30 min, which was already significant (P &lt; 0.0001) by 5 min. By contrast, skin temperature decreased significantly (P &lt; 0.0001) in the hand after failed blocks and in the contra-lateral non-blocked hand by -1.5°C (-6.2 to 4.2).&lt;h4&gt;Conclusion&lt;/h4&gt;Successful IBPB resulted in four thermographic patterns. Skin temperature always increased on the thumb within 30 min and this increase achieved statistical significance at 5 min after the block.},
	URL = {https://doi.org/10.1097/EJA.0000000000000152},
}





@article{https://doi.org/10.1111/anae.12927,
author = {Hoyle, J. and Yentis, S. M.},
title = {Assessing the height of block for caesarean section over the past three decades: trends from the literature},
journal = {Anaesthesia},
volume = {70},
number = {4},
pages = {421-428},
doi = {https://doi.org/10.1111/anae.12927},
url = {https://associationofanaesthetists-publications.onlinelibrary.wiley.com/doi/abs/10.1111/anae.12927},
eprint = {https://associationofanaesthetists-publications.onlinelibrary.wiley.com/doi/pdf/10.1111/anae.12927},
abstract = {Summary There are multiple methods of assessing the height of block before caesarean section under regional anaesthesia, and surveys of practice suggest considerable variation in practice. So far, little emphasis has been placed on the guidance to be gained from published research literature or textbooks. We therefore set out to investigate the methods of block assessment documented in published articles and textbooks over the past 30 years. We performed two searches of PubMed for randomised clinical trials with caesarean section and either spinal anaesthesia or epidural anaesthesia as major Medical Subject Headings. A total of 284 papers, from 1984 to 2013, were analysed for methods of assessment of sensory and motor block, and the height of block deemed adequate for surgery. We also examined 45 editions of seven anaesthetic textbooks spanning 1950–2014 for recommended methods of assessment and height of block required for caesarean section. Analysis of published papers demonstrated a wide variation in techniques, though there has been a trend towards the increased use of touch, and an increased use of a block height of T5 over the study period. Only 115/284 (40.5\%) papers described the method of assessing motor block, with most of those that did (102/115; 88.7\%) describing it as the ‘Bromage scale’, although only five of these (4.9\%) matched the original description by Bromage. The required height of block recommended by textbooks has risen over the last 30 years to T4, although only four textbooks made any recommendation about the preferred sensory modality. The variation in methods suggested by surveys of practice is reflected in variation in published trials, and there is little consensus or guidance in anaesthetic textbooks.},
year = {2015}
}


@article{CHAE2022104744,
title = {Pain modalities in the body and brain: Current knowledge and future perspectives},
journal = {Neuroscience \& Biobehavioral Reviews},
volume = {139},
pages = {104744},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104744},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422002330},
author = {Younbyoung Chae and Hi-Joon Park and In-Seon Lee},
keywords = {Pain, Modality specificity, Biomarker, Functional neuroimaging, Precision medicine},
abstract = {Development and validation of pain biomarkers has become a major issue in pain research. Recent advances in multimodal data acquisition have allowed researchers to gather multivariate and multilevel whole-body measurements in patients with pain conditions, and data analysis techniques such as machine learning have led to novel findings in neural biomarkers for pain. Most studies have focused on the development of a biomarker to predict the severity of pain with high precision and high specificity, however, a similar approach to discriminate different modalities of pain is lacking. Identification of more accurate and specific pain biomarkers will require an in-depth understanding of the modality specificity of pain. In this review, we summarize early and recent findings on the modality specificity of pain in the brain, with a focus on distinct neural activity patterns between chronic clinical and acute experimental pain, direct, social, and vicarious pain, and somatic and visceral pain. We also suggest future directions to improve our current strategy of pain management using our knowledge of modality-specific aspects of pain.}
}

@article{nelson2018survey,
	title={A survey of current anesthesia trends for electrophysiology procedures},
	author={Nelson, Eric W and Woltz, Erick M and Wolf, Bethany J and Gold, Michael R},
	journal={Anesthesia \& Analgesia},
	volume={127},
	number={1},
	pages={46--53},
	year={2018},
	publisher={LWW}
}

@INPROCEEDINGS{9319081,
  author={Tiator, Marcel and Kerkmann, Anna Maria and Geiger, Christian and Grimm, Paul},
  booktitle={2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
  title={Using Semantic Segmentation to Assist the Creation of Interactive VR Applications}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/AIVR50618.2020.00011}}





@article{CASTIGLIONI20219,
title = {AI applications to medical images: From machine learning to deep learning},
journal = {Physica Medica},
volume = {83},
pages = {9-24},
year = {2021},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2021.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1120179721000946},
author = {Isabella Castiglioni and Leonardo Rundo and Marina Codari and Giovanni {Di Leo} and Christian Salvatore and Matteo Interlenghi and Francesca Gallivanone and Andrea Cozzi and Natascha Claudia D'Amico and Francesco Sardanelli},
keywords = {Artificial intelligence, Deep learning, Machine learning, Medical imaging, Radiomics},
abstract = {Purpose
Artificial intelligence (AI) models are playing an increasing role in biomedical research and healthcare services. This review focuses on challenges points to be clarified about how to develop AI applications as clinical decision support systems in the real-world context.
Methods
A narrative review has been performed including a critical assessment of articles published between 1989 and 2021 that guided challenging sections.
Results
We first illustrate the architectural characteristics of machine learning (ML)/radiomics and deep learning (DL) approaches. For ML/radiomics, the phases of feature selection and of training, validation, and testing are described. DL models are presented as multi-layered artificial/convolutional neural networks, allowing us to directly process images. The data curation section includes technical steps such as image labelling, image annotation (with segmentation as a crucial step in radiomics), data harmonization (enabling compensation for differences in imaging protocols that typically generate noise in non-AI imaging studies) and federated learning. Thereafter, we dedicate specific sections to: sample size calculation, considering multiple testing in AI approaches; procedures for data augmentation to work with limited and unbalanced datasets; and the interpretability of AI models (the so-called black box issue). Pros and cons for choosing ML versus DL to implement AI applications to medical imaging are finally presented in a synoptic way.
Conclusions
Biomedicine and healthcare systems are one of the most important fields for AI applications and medical imaging is probably the most suitable and promising domain. Clarification of specific challenging points facilitates the development of such systems and their translation to clinical practice.}
}

@Article{electronics11121884,
AUTHOR = {Alokasi, Haneen and Ahmad, Muhammad Bilal},
TITLE = {Deep Learning-Based Frameworks for Semantic Segmentation of Road Scenes},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {12},
ARTICLE-NUMBER = {1884},
URL = {https://www.mdpi.com/2079-9292/11/12/1884},
ISSN = {2079-9292},
ABSTRACT = {Semantic segmentation using machine learning and computer vision techniques is one of the most popular topics in autonomous driving-related research. With the revolution of deep learning, the need for more efficient and accurate segmentation systems has increased. This paper presents a detailed review of deep learning-based frameworks used for semantic segmentation of road scenes, highlighting their architectures and tasks. It also discusses well-known standard datasets that evaluate semantic segmentation systems in addition to new datasets in the field. To overcome a lack of enough data required for the training process, data augmentation techniques and their experimental results are reviewed. Moreover, domain adaptation methods that have been deployed to transfer knowledge between different domains in order to reduce the domain gap are presented. Finally, this paper provides quantitative analysis and performance evaluation and discusses the results of different frameworks on the reviewed datasets and highlights future research directions in the field of semantic segmentation using deep learning.},
DOI = {10.3390/electronics11121884}
}






@article{kriti2022characterization,
  title={A characterization approach for the review of CAD systems designed for breast tumor classification using B-mode ultrasound images},
  author={Kriti and Virmani, Jitendra and Agarwal, Ravinder},
  journal={Archives of Computational Methods in Engineering},
  pages={1--39},
  year={2022},
  publisher={Springer}
}


@article{LUO2023,
title = {Semantic segmentation of agricultural images: A survey},
journal = {Information Processing in Agriculture},
year = {2023},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2023.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2214317323000112},
author = {Zifei Luo and Wenzhu Yang and Yunfeng Yuan and Ruru Gou and Xiaonan Li},
keywords = {Semantic segmentation, Agricultural images, Deep learning, Convolution neural networks},
abstract = {As an important research topic in recent years, semantic segmentation has been widely applied to image understanding problems in various fields. With the successful application of deep learning methods in machine vision, the superior performance has been transferred to agricultural image processing by combining them with traditional methods. Semantic segmentation methods have revolutionized the development of agricultural automation and are commonly used for crop cover and type analysis, pest and disease identification, etc. We first give a review of the recent advances in traditional and deep learning methods for semantic segmentation of agricultural images according to different segmentation principles. Then we introduce the traditional methods that can effectively utilize the original image information and the powerful performance of deep learning-based methods. Finally, we outline their applications in agricultural image segmentation. In our literature, we identify the challenges in agricultural image segmentation and summarize the innovative developments that address these challenges. The robustness of the existing segmentation methods for processing complex images still needs to be improved urgently, and their generalization abilities are also insufficient. In particular, the limited number of labeled samples is a roadblock to new developed deep learning methods for their training and evaluation. To this, segmentation methods that augment the dataset or incorporate multimodal information enable deep learning methods to further improve the segmentation capabilities. This review provides a reference for the application of image semantic segmentation in the field of agricultural informatization.}
}



@inproceedings{10.1145/2992138.2992144,
author = {Lin, Jenny and Guo, Xingwen and Shao, Jingyu and Jiang, Chenfanfu and Zhu, Yixin and Zhu, Song-Chun},
title = {A Virtual Reality Platform for Dynamic Human-Scene Interaction},
year = {2016},
isbn = {9781450345484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2992138.2992144},
doi = {10.1145/2992138.2992144},
abstract = {Both synthetic static and simulated dynamic 3D scene data is highly useful in the fields of computer vision and robot task planning. Yet their virtual nature makes it difficult for real agents to interact with such data in an intuitive way. Thus currently available datasets are either static or greatly simplified in terms of interactions and dynamics. In this paper, we propose a system in which Virtual Reality and human / finger pose tracking is integrated to allow agents to interact with virtual environments in real time. Segmented object and scene data is used to construct a scene within Unreal Engine 4, a physics-based game engine. We then use the Oculus Rift headset with a Kinect sensor, Leap Motion controller and a dance pad to navigate and manipulate objects inside synthetic scenes in real time. We demonstrate how our system can be used to construct a multi-jointed agent representation as well as fine-grained finger pose. In the end, we propose how our system can be used for robot task planning and image semantic segmentation.},
booktitle = {SIGGRAPH ASIA 2016 Virtual Reality Meets Physical Reality: Modelling and Simulating Virtual Humans and Environments},
articleno = {11},
numpages = {4},
keywords = {virtual reality, benchmark suite, 3D scene dataset},
location = {Macau},
series = {SA '16}
}